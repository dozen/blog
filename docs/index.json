[{"content":"\n\n## 謝辞\nチームMSAのken39argさん、mizkeiさん、ありがとうございました。\nISUCON運営に関わられた皆さんどうもありがとうございました。\n\n## 出題\nhttps://github.com/isucon/isucon7-final/blob/master/manual.pdf\n\nISUCON 7本戦のマニュアルが公開されておりますので、参照ください。\n\n簡単に構成を紹介すると、CPU 2コア, メモリ2GB, ネットワーク帯域500Mbpsのサーバが4台で、うち3台がnginx + appサーバで1台がDBサーバという状態でした。\n\nWebsocketという単語が出題ムービー(?)で出てきて全然わからないけど大丈夫かな…っていうのと、仕様の説明が全く理解できなくてポカーンとしてしまい初っ端から意識を失いかけました。\n\n## やったこと\n- 環境整備\n- サーバのメトリクス監視\n- ミドルウェアのチューニング・構成変更\n\n予選同様、アプリ側の改善はken39argさん、mizkeiさんにやってもらい、私は環境整備とインフラ側を分担するという役割です。\n環境整備をしてる間にミドルウェアの設定をrepoに入れたりとかはインフラ側の仕事っぽいですが、これはken39argさんがササッっとやってくださいました。\n\n### 競技開始\n予選同様、まず環境整備に取り組みました。\n\n- パスワードなしでログインできるようにする\n- サーバ間の行き来を簡単にする\n- PRベースで開発できるようにgoのソースをrepoに入れる\n- makeでデプロイ自動化\n\n予選と同じことをするだけだったはずなんですが、手間取ってしまった上、デプロイ自動化のためのMakefileはバグってるものをmergeしてしまったりという感じでした。\n\n### 初期構成でベンチ\n初期構成でベンチをかけたところ、appサーバ、DBサーバ共にすべてのリソースが余っている状況で、DBは10~20%くらいのiowaitが発生していました。\nCPUが遊んでいてメモリも余っている、ネットワークもディスクもそれほどスループットが出ているわけではない、一見してボトルネックらしいボトルネックが確認できなかったのですが、この時点ではDBかな?と思っていました。\n\n### その後\nアプリの改善がいくつか入った後も余りスコアが伸びず、やはりリソースは余っており何がボトルネックになっているのか依然としてつかめませんでした。\n\nDBのiowaitが足を引っ張っているのかと疑ってみて、MySQLの様子を見てみることにしました。\nとりあえず innodb buffer pool を確認してみましたが、128MBでも余っているので関係ないと判断していじらずに放置。\ninnodb buffer pool が余っていることと、クエリの比率を見てみたところ更新系の比率が高かったことを考え、 innodb_flush_log_at_trx_commit かなと思い\n`innodb_flush_log_at_trx_commit=0` を設定したところiowaitがなくなりました。\niowaitが消滅したisu4のCPUは完全に遊んでいて、DBがボトルネックじゃなかったんだと気付きます。\n最初にアプリの二人にボトルネックはDBですかね…と間違ったことを伝えてしまったので、早い段階で正しい判断ができていればもっと良い方向へ向かったかもしれません。\n\nアプリ側の改善がその後続き、だんだんとappサーバのCPU使用率が上昇し、CPUを使えている状態になっていきました。\nMySQLはというとどんどん参照系のクエリが減少し、更新系の占める比率が上昇していく流れでした。\n\n最終的にはisu4のCPU使用率が1%とかになっていたため、これはもうisu4にもappサーバ置くべきだろうということになり、全台にappを置くことにしました。\n\n## 結局私は何をやったのか?\nスコアに寄与する変更は\n\n- isu4に app を配置した\n- mysqlに innodb_flush_log_at_trx_commit=0 を設定した\n\nの2つしかありません。そして `innodb_flush_log_at_trx_commit` はiowaitの20%分くらいを稼いだに過ぎないので、贔屓目に見てもせいぜい1000くらいしか加点になっていないのでは無いかと思います。\n\n## 迷走中にしたこと\nその他にもMySQLのパラメータに問題がないか疑ってみたり、アプリのチューニング以外にできることはないかと思っていくつか取り組んだことがありますが、これらに特に意味はなかったようです。\n\n### nginxでgzip_static の設定, worker_connections を増やす\nこれは迷走ではなくまっとうなチューニングですが、スコアが低下したため不採用。\nworker_connectionsは適当に増やしたのでまっとうとは言えないかもしれないです。\n\n### HTTP2\n- FQDNが与えられている\n- nginxになんかSSLの設定が入っている\n- appのCPUは遊んでいる\n- worker_connection 増やしても接続数上がらない\n\nということで、ベンチマーカはTCP層で接続数をしぼっているが、HTTP2にすると並列度が上がるというパターンなのではないか?みたいな雰囲気でやっていました。\n結局のところ、アプリのチューニングでCPU使用率が上ってきたため、これは違うなと考えて捨てました。\nLet's Encryptで4台分の証明書を作るといった奇行をしていましたが、これは懇親会で先輩に話したときけっこう受けたので、最悪に不毛だったんですが良しとします。\n\n## 振り返り\n他のチームと比べると明らかにインフラがプアで、このチーム編成で優勝できたのはアプリがヘビーだったからだと思っています。\n\n自分ができるやつだとは思っていないつもりですが、ここまでしょぼいとだいぶ凹みます。\nチームとしては優勝できましたが、これは完全にken39argさんとmizkeiさんのおかげでしかありませんね。\n\nとはいえ優勝できたのはとても嬉しいです。mizkeiさん、ken39argさん、本当にありがとうございました。\nこのチームでISUCONに参加できてとても良かったと思います。\n\n自分の未熟さを知る良い機会でした。この事実を受け止め、精進します🐘\n","cover":"","link":"2017/11/29.html","preview":"\u003cp\u003eチームMSAとしてISUCON 7 本戦に出場しました\u003c/p\u003e\n","title":"ISUCON 7 で優勝してきました"},{"content":"\n\nISUCON7にチームMSA(@ken39arg, @mizkei, @suzuki)として参加してきました。\n\n今回は予選に参加したチームが400組を超え、1チームに割り当てられるサーバも3台でしたから土日合わせて1200台ものインスタンスを準備したということになります。\n運営チームの方々、ありがとうございました。\n\n\n## チームMSA\n@mizkeiさんがチームメイトを募集していて、私も参加しようと思ってはいたんですが誰も組む相手がいない…という状況でしたので、ぜひご一緒しましょうということで参加させてもらいました。あと一人どうしようかと思っているときに来てくれたのが@ken39argさんです。\n\n- ken39arg\n  - アプリ・インフラ担当\n  - 経験がすごい\n  - 実装スピードがすごい\n  - インフラ\n  - ミドルウェア周りも手伝ってもらいました\n  - ブログ: http://ken39arg.hatenablog.com/entry/2017/10/24/002546\n- mizkei\n  - アプリ担当\n  - 実装スピードがすごい\n  - Goが好きすぎる\n  - ブログ: http://mizkei.hatenablog.com/entry/2017/10/23/182820\n- 私\n  - インフラ担当\n\nチーム名は3人の頭文字です。なんでこの順番かは@ken39argさんが知っているかもしれません。\n\n## やったこと\nインフラ周り以外はノータッチで、アプリのコードは全く見ませんでした。アプリの読み込み・改修は完全にkens39argさんとmizkeiさんにお願いしていて、私はインフラのタスクだけをしていました。\nなのでその辺に関しては二人のブログを参照されるのが良いと思います。\n\n### 事前準備\n複数台のサーバを管理しやすくするために、repoを作ってサクッと環境構築できるchefのレシピを用意しておきました。\n\n- 3人のユーザを用意\n  - `http://github.com/{username}.keys` が便利です\n- root, appユーザでサーバ間をsshで移動できるようにする\n  - ついでにroot, appユーザの公開鍵をdeployキーとして登録しておきます\n  - あとhostsで自分たちがやりやすいホスト名を設定、例えばisu1~isu3みたいにしておくと便利\n- 全台でchefを回したり、repoを全台に配るMakefileを用意\n\n### 当日\n- 事前に用意しておいたchefを回す\n- mysqlのslowlogを出すようにする\n- ミドルウェアの設定・アプリを全台にデプロイするMakefileを作成\n- 構成確認\n- go実装へ切り替え\n- goのコードをrepoに入れる\n- alpのログ取れるようにnginxのログフォーマットをltsvに\n- 最初のベンチを実行\n  - pprof, alp, pt-query-digest でログ解析\n  - dstatを眺める\n\nとりあえず以上のことをやりました。\n\n初期ユーザ名/パスワードで全員がログインし、分担して作業を進めていきました。私はchefを回したりアプリのデプロイができるように環境を整える仕事をしていました。\n\n構成確認では3台ともCPU 1コア, メモリ 1GB, スワップ 4GBであることを把握しました。全体的にリソースが少ないというのはもちろんですが、スワップがきになるぞ、という感想。一応心の隅に留めておきます。\nアプリの構成とレギュレーションで公開されているネットワーク帯域幅も加えてまとめると、以下のようになります。\n\n- CPU 1コア, メモリ1GB, スワップ4GB のサーバ3台\n  - nginx + app x 2\n  - mysql x 1\n- WAN帯域 100Mbps\n- LAN帯域 500Mbps\n\ngo実装に切り替えて初回のベンチを回したところ、dstatでMySQLサーバがLAN側のネットワークを500Mbps以上も使っており、帯域制限に確実に引っかかっている状態。まずLAN帯域がボトルネックになっているという状況でした。\nこれは一体どういうことなんだと思ったのですが、実装とslowlogをみてもらったアプリ担当の二人から画像データをBLOB型のカラムに保存してたと聞いたので、これが原因なのかな？と思いました。\n\nともかくDBから画像を剥がさないことには何も始まらないという共通の見解を得たため、初期データの画像ファイルをファイルに書き出すのと画像をファイルシステムに保存するようにアプリを変更する作業をmizkeiさんが行い、ken39argさんがアプリを読んでINDEXを張っていくのと静的ファイルを参照するようにnginxの設定を書き換えるという作業を行なっていました。\n\nその間に私が何をしていたかというと、何もしてません。DBに入っている初期画像データをファイルに落とすというのが当初の担当だったんですが、失敗し続けていたのでmizkeiさんにお願いしたためです。ken39argさんが書いてくれたnginxの設定をレビューしたくらいですかね…。\n\n画像データを引っこ抜くのなんてわけないだろうと思ってmysqlコマンドを使ったシェルのワンライナーを書いたんですが全くうまくいかず、これなら絶対うまく行くと思ってcurlでアイコン画像のエンドポイントを叩いて画像ファイルを保存してみても上手くいかずでしょんぼりしました。\n\n画像をDBから剥がした結果、以下のような構成になりました。 `*`がついているサーバがベンチマーカのリクエストを受け付けます。\n\n- *isu1: nginx (`GET /icons` `POST /profile` 以外) + app\n- *isu2: nginx (`GET /icons` `POST /profile` 以外) + app\n-  isu3: nginx (`GET /icons` `POST /profile` のみ) + app + DB\n\nisu1とisu2ではnginxで`GET /icons`と`POST /profile`をisu3に流してしまい、画像のアップロードと画像ファイルの配信はisu3のnginx + appが担当するようにしました。\nこれでLAN帯域のボトルネックが消えたため、スコアが上がったはず（覚えてない）。\n\nここからアプリ担当のken39argさんとmizkeiさんがものすごい勢いでアプリのリファクタリングに入りました。この間のスコア計測中にページアウトが発生し始めたので全台の`vm.swappiness`を1にセット。いくつかアプリの改善でスコアが上昇しましたが、アプリサーバもDBサーバもCPUが遊んでおりスコアが伸び悩みます。\ndstatからWAN帯域がサチっているということがわかったので、静的ファイルのキャッシュをするようnginxの設定をしたところ、304を返せるようになりスコアが劇的に上昇。スコアが伸び悩む中黙々とアプリの改善をしてきた成果が現れました。\n\nその後もアプリの改善は続き、スコアはどんどん伸びていきました。初めてMySQLサーバのCPUリソースがボトルネックとなり、再びDBだけのサーバとするため以下のような構成を取ることにしました。\n\n- *isu1: nginx + app\n- *isu2: nginx + app\n-  isu3: DB\n\nisu1, isu2はそれぞれが`POST /profile`を受け付け、ローカルにアイコン画像を保存します。アップロードされた画像はどちらか一方にしか保存されないため、ローカルにないファイルへのリクエストが来た場合はもう一方のサーバを見に行くようnginxを設定することにしました。\nこの設定を適用した後、アイコン画像が表示されなくなってしまったため、お互いのサーバを参照する設定がまずかったのかと思いisu2だけにアイコン画像を保存する設定に変更しました。しかし、実際にはisu3にあった初期画像ファイルをisu1, isu2にコピーした時にコピー先を間違えていたのが原因でした。\n上記の問題で関係のないアプリの変更PRにも不具合があるように見えてしまい、不具合がないアプリの見直しをmizkeiさんにさせてしまうという、アプリを巻き込んでハマってしまうという大事故を起こしました。本当に申し訳なかったです。\n\nようやくこの構成がまともに動くようになるとスコアは46万点を記録しました。アプリサーバは遊んでいるがMySQLサーバはCPUを食っていてIOwaitが出始めているという状況だったので、innodb_buffer_pool_sizeしかいじっていなかったMySQLのチューニングをする流れになりました。\ninnodb_buffer_pool_sizeを増やしてベンチマークをかけるとスコアががくんと落ちたため、まずかったかと急いで戻して再度ベンチマークをかけるとさらにスコアが落ち、そんなことをしている間に2万点まで落ち込み大騒ぎになりました。\n\nここで競技終了まで1時間30分というところです。DBサーバに問題があるのかとずっと調べていましたが、原因はアプリサーバで発生していたページアウトでした。アプリがメモリを食っているということで、アプリ担当の二人に調べてもらったところ、アイコン画像のアップロード部分で`ioutil.ReadAll`を使っているのが原因だろうということをアプリ担当の二人が突き止めたのは競技終了まで40分の時点でした。\n\n再起動試験をする余裕なども考えると安全圏ではないという結論に至り、アプリの修正はされませんでした。アプリを再起動すれば1回のベンチには耐えることを確認した為、このままにすることにしました。\n\n競技開始してからスコア計測時は必ず全サーバのモニタリングをしていたはずなのに最後にスワップを見落として全員を道に迷わせたのが辛かったです。計測中はdstatひたすらみてたのに、スワップに気づいたのはなんとなく打ったfreeコマンドでした…\nまあ、freeで気付いた時はスコア計測中ではなかったので`dstat -af`で表示しているpage in/outの値は判断しようがないです、が、その場合でもメモリ使用量でアプリが異常にメモリを消費していることに気づくべきですし、スコア計測中は page out が頻発していたのを見逃していたということですのでどのみちダメダメでしたね。\n\n## 終わってみて思うこと\n1位で通過できたのは非常に嬉しかったんですが、ブログを書いたりgit logを見返しているうちに自分の仕事ぶりを冷静に振り返ることになります。\n\n手が遅いというのはかなり感じたんですが、速度以外にも能力不足な点が多くあり、二人の足を引っ張る場面があったと思います。インフラ側がしっかりしてれば防げたトラブル、加点要素がいくつも思い当たりますし、インフラの仕事も全部こなせなかったので情けないですね。\n\nそういえば私は普段ken39argさんやmizkeiさんと一緒に働いているわけではないのですが、競技中にやりにくさとかは全く感じませんでしたし、特に不安感もなかったです。これはとても良いことだったなと思います。\n\n今回は予選から複数台構成での戦いということでしたが、チューニング以前に複数のサーバに役割を持たせてサービスを運用することにまず魅力を感じるので、例年では本選に行かないと味わえない複数台構成でのISUCONが予選から体験できるのは最高だと思いました。\n\nそれと、終わった後にisu3にnginxだけ置くための設定ファイルを用意していたので入れていたかもしれないとメンバーに言ったのですが、実際あの時の私がそれを入れるようなことは絶対になかったと思うので、嘘をつきました。\nMySQLのiowaitを解消したら入れてたかもしれないですね、みたいな言い方をしていたんですが、おそらくMySQLのチューニングでiowaitが解消されてまたCPUが天井に張り付くのをみたら、MySQLのCPUリソースは1ミリも割きたくないのでこのままにする、という選択をしていたと思います。\n\n3台構成にする利点はWAN帯域を300Mbps確保できることですが、終盤に2台でベンチマーカからリクエストを受け付ける構成でもスコア計測中のボトルネックはDBサーバのCPUで、WAN帯域を200Mbps使い切ってはいなかったと思います。\nただし、スコア計測が始まってすぐはキャッシュされるアイコン画像などもきちんと返す必要があるため、帯域を使い果たしていたはず。\nその立ち上がりの詰まりを取り除けると、早い段階から負荷がかかる（段階的に負荷を上げてくるという特性も把握してなかった）ため60秒で効率的にベンチを回せるためスコアが伸びるということだと思います（ほかのチームのブログにそんなことが書いてあったような気がします）。\n私はスコア計測の初期にWANが刺さっていることと、ベンチマーカの特性の両方を把握していなかったので、DBサーバのCPUを削って帯域を広げるのは全く考えにありませんでした。\n3台構成にしたチームの話を聞いたから、後出しでこんなものを用意していましたと言ってしまったんですが、これはかなり格好悪いですね。\n\n自分の未熟さが良くわかったし大いに反省したので、これから伸ばして行きたいです。\n\n1ヶ月後の本選も頑張ります。チームの皆さん、よろしくお願いします。🐘\n","cover":"","link":"2017/10/26.html","preview":"\u003cp\u003eチームMSAのインフラ担当として参加して来ました\u003c/p\u003e\n","title":"ISUCON 7 予選1日目を1位で通過して来ました"},{"content":"\n\n`bcm2708-rng`はラズパイのハードウェア乱数生成器を使用するためのカーネルモジュールですが、それが読み込めて無くて `systemd-modules-load.service`がコケていました。\n\n```\n● systemd-modules-load.service - Load Kernel Modules\n   Loaded: loaded (/usr/lib/systemd/system/systemd-modules-load.service; static; vendor preset: disabled)\n   Active: failed (Result: exit-code) since Wed 2017-02-01 10:11:51 JST; 20s ago\n     Docs: man:systemd-modules-load.service(8)\n           man:modules-load.d(5)\n  Process: 850 ExecStart=/usr/lib/systemd/systemd-modules-load (code=exited, status=1/FAILURE)\n Main PID: 850 (code=exited, status=1/FAILURE)\n\n 2月 01 10:11:51 pi systemd[1]: Starting Load Kernel Modules...\n 2月 01 10:11:51 pi systemd-modules-load[850]: Failed to find module 'bcm2708-rng'\n 2月 01 10:11:51 pi systemd[1]: systemd-modules-load.service: Main process exited, code=exited, status=1/FAILURE\n 2月 01 10:11:51 pi systemd[1]: Failed to start Load Kernel Modules.\n 2月 01 10:11:51 pi systemd[1]: systemd-modules-load.service: Unit entered failed state.\n 2月 01 10:11:51 pi systemd[1]: systemd-modules-load.service: Failed with result 'exit-code'.\n```\n\nいつの間にかサポートされなくなってたみたいです。\n\n\u003ca href=\"https://archlinuxarm.org/forum/viewtopic.php?f=64\u0026t=10153\" target=\"_blank\"\u003eArch Linux ARM • View topic - Solved: RPi 2: bcm2708-rng module missing after update\u003c/a\u003e\n\n`/etc/modules-load.d/raspberrypi.conf`に読み込むカーネルモジュールを列挙していましたが、`bcm2708-rng`の代わりに`bcm2835-rng`を使うよう変更しました。\n\n```\n● systemd-modules-load.service - Load Kernel Modules\n   Loaded: loaded (/usr/lib/systemd/system/systemd-modules-load.service; static; vendor preset: disabled)\n   Active: active (exited) since Sat 2017-05-06 00:31:18 JST; 2s ago\n     Docs: man:systemd-modules-load.service(8)\n           man:modules-load.d(5)\n  Process: 2385 ExecStart=/usr/lib/systemd/systemd-modules-load (code=exited, status=0/SUCCESS)\n Main PID: 2385 (code=exited, status=0/SUCCESS)\n\n 5月 06 00:31:18 pi systemd[1]: Starting Load Kernel Modules...\n 5月 06 00:31:18 pi systemd[1]: Started Load Kernel Modules.\n```\n\n無事systemd-modules-loadが起動できました🐘\n","cover":"","link":"2017/05/06.html","preview":"","title":"systemd-modules-loadがコケる"},{"content":"\n\nRaspberry Pi2にはRTCがありませんが、これによって再起動したときに時刻が `2017年1月1日` とかになります。\n\nシステム時刻が現在時刻とかけ離れている場合、NTPによる同期が失敗することがあり、ラズパイを再起動するといつまでたっても正しい時刻に戻ってくれず大変困ります。\n\nRTCモジュール買えば良いんですが、再起動したときにササッとNTPに同期できるようにしたいだけなので、タダで済ませたいところです。\n\nそこで、再起動する直前の時刻時刻をファイルに書き出しておき、再起動後にセットすることでNTPと同期できる程度の差に抑えることにしました。\n\n\u003ca href=\"https://github.com/dozen/myrtc\" target=\"_blank\"\u003edozen/myrtc - Github\u003c/a\u003e\n\nRaspberry Pi2にはArchlinuxを入れているので、systemdで使えるようにしました。\n\n`myrtc` を `/usr/local/myrtc/` に置いて、 `myrtc.service` を `/etc/systemd/system/` に置きます。\n\n`/usr/local/myrtc/myrtc store` で現在時刻をファイルに保存し、 `/usr/local/myrtc/myrtc restore` でファイルに書き出した時刻をシステム時刻にセットします。\n\n`restore` にはroot権限が必要です。\n\n`myrtc.service` はonshotタイプのサービスで、start時に`restore`コマンドを実行し、stop時に`store`コマンドを実行することで、起動時に`restore`、シャットダウン時に`store`を実行できるようにしています。\n\n再起動にかかる時間は考慮されていないので、myrtcでセットし直した時刻は、私のRaspberry Pi2でだいたい30秒くらい遅れます。storeかrestoreどちらかでその間に進む時刻を大体で加算すればもっと誤差が小さくなりそうですが、NTPで同期できればそれでいいので、ややこしいことはしていません。\n\nもし不慮のシャットダウンなども考慮したい場合は、cronで`myrtc store`を定期的に実行するか、 myrtcコマンドを書き換えて無限ループの中でスリープを挟みながら時刻をファイルに書き出し続ける、みたいにすればいい感じになりそうです。\n\nもし後者のmyrtcを書き換えるパターンを実践する場合は、 `myrtc.service` を書き換える必要がありますね。\n\nともかくこれでRaspberry Pi2を再起動したとき、毎回 `date -s …` と打ち込まずに済むようになりました。\n\n\n追記\n\n`tinker panic 0`とすればどんなに時刻がずれていても同期してくれるので、こんな物はいらないですね…🐘\n","cover":"","link":"2017/05/05.html","preview":"\u003cp\u003e再起動したときntpで同期できないのが辛いので\u003c/p\u003e\n","title":"RaspberryPi2用のRTCもどきを作る"},{"content":"\n\n# Base128とは\n英数字(a-z, A-Z, 0-9)とひらがな(あ-ん)の128文字を使ってバイト列をエンコードするものです．\n実用性はともかく，文字数はBase64より少なくなるというメリットがあります．\nデメリットは，エンコード後のデータ量がものすごく増えることと，元のデータ量に対して一定でないことです．\n\n\u003ca href=\"https://github.com/dozen/encoding\" target=\"_blank\"\u003eGithub: dozen/encoding\u003c/a\u003e\n\n# 使い方\n\n## import\n```\nimport \"github.com/dozen/encoding/base128\"\n```\n\n## encode\n```\ne := base128.NewEncoding(base128.StdEncoding)\n\ne.EncodeToString([]byte(\"Hello, world!\")) //=\u003ekZtけふ8ぢg7どぺmふQお\n```\n\n## decode\n```\ne := base128.NewEncoding(base128.StdEncoding)\n\nfmt.Printf(\"%s\\n\", e.Decode(\"kZtけふ8ぢg7どぺmふQお\")) //=\u003eHello, world!\n```\n\n# 実装\nBase64を参考にして作り始めたのですがとりあえず動くようにしようとあれこれしている間に全く別物になってしまいました．\n\nBase64の場合，64文字を用いるので6bitを表現できます．エンコード時には，元の8bitのバイト列を6bitに区切るために，4byteずつuintに格納してから6bitずつビットシフトしています。\n\n```\nval := uint(src[si+0])\u003c\u003c16 | uint(src[si+1])\u003c\u003c8 | uint(src[si+2])\n\ndst[di+0] = enc.encode[val\u003e\u003e18\u00260x3F]\ndst[di+1] = enc.encode[val\u003e\u003e12\u00260x3F]\ndst[di+2] = enc.encode[val\u003e\u003e6\u00260x3F]\ndst[di+3] = enc.encode[val\u00260x3F]\n```\n\nこんなかんじです．\u003ca href=\"https://golang.org/src/encoding/base64/base64.go\" target=\"_blank\"\u003eencoding/base64/base64.go\u003c/a\u003eの100行目ぐらいのところです．\n\nこれを参考にして，元の8bitのバイト列を7byteずつ取り出し，7bitずつ区切ることにしました．7byte=56bitなのでuintには収まる範囲です．\n\n\n```\nval :=\tuint(src[si+0])\u003c\u003c48 |\n\tuint(src[si+1])\u003c\u003c40 |\n\tuint(src[si+2])\u003c\u003c32 |\n\tuint(src[si+3])\u003c\u003c24 |\n\tuint(src[si+4])\u003c\u003c16 |\n\tuint(src[si+5])\u003c\u003c8 |\n\tuint(src[si+6])\n\ndst[di+0] = enc.encode[val\u003e\u003e49\u00260x7F]\ndst[di+1] = enc.encode[val\u003e\u003e42\u00260x7F]\ndst[di+2] = enc.encode[val\u003e\u003e35\u00260x7F]\ndst[di+3] = enc.encode[val\u003e\u003e28\u00260x7F]\ndst[di+4] = enc.encode[val\u003e\u003e21\u00260x7F]\ndst[di+5] = enc.encode[val\u003e\u003e14\u00260x7F]\ndst[di+6] = enc.encode[val\u003e\u003e7\u00260x7F]\ndst[di+7] = enc.encode[val\u00260x7F]\n```\n\nこのようになります．\n\nエンコード後の文字列にUTF-8を含むのでBase64そっくりそのままというわけにはいかず，そのへんで躓きました．\n\nまた，Base64は3byteを4文字で表現する際に終端が4文字に満たないとき，`=`で埋めるという処理があります．`encoding/base64`では`NoPadding`を指定すれば`=`埋めをしないような処理にも出来ます．\n\nこの終端の`=`埋め処理をBase128ではしていません．切り替えられるようにするべきですが，まだしていません．Base128において`=`をした場合，最大で6文字の`=`が並びます．これはちょっと嫌です．\n\nこのBase128は使いみちが思いつきませんが，Base256というのも作ってみようかと思います．漢字を含めれば8bitを表現できそうですし，8bitで元のバイト列をnbitへ切り分ける，といった処理をしなくていいのでもっと簡単に作れるような気がします．\n\nそういえば，`uint`は環境によってサイズが変わるので，`uint64`を使わないと，32ビット環境でちゃんと動かないですね．これは直さないといけないです．🐘\n","cover":"","link":"2016/10/24.html","preview":"\u003cp\u003e英数字とひらがなでエンコードします\u003c/p\u003e\n","title":"Base128を作りました．"},{"content":"\n\n# Go言語におけるXML文書の扱い方\n\nUTF-8のXML文書の扱い方についてはここを参考にしました．\n\nhttp://qiita.com/ono_matope/items/70080cc33b75152c5c2a\n\n# Shift_JISのXML文書\n\n上のリンクを参考にしてXMLファイルをパースしようと思ったら，ファイルの文字コードがShift_JISだったのでうまくいきませんでした．\n\n\n```\n\u003c?xml version=\"1.0\" encoding=\"Shift_JIS\"?\u003e\n\u003cuser\u003e\n\t\u003cName\u003e太郎ちゃん\u003c/Name\u003e\n\t\u003cattr\u003eMale\u003c/attr\u003e\n\t\u003cage\u003e20\u003c/age\u003e\n\u003c/user\u003e\n```\n\nこのようなXMLファイルを次のようなコードでパースしようとしましたら失敗しました．\n\n```\npackage main\n\nimport (\n\t\"os\"\n\t\"fmt\"\n\t\"encoding/xml\"\n)\n\nfunc main() {\n\tfp, _ := os.Open(\"taro.xml\")\n\tdefer fp.Close()\n\n\tvar user User\n\tdecoder := xml.NewDecoder(fp)\n\terr = decoder.Decode(\u0026user)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t}\n\n\tfmt.Printf(\"%#v\", user)\n}\n\ntype User struct {\n\tXMLName xml.Name `xml:\"user\"`\n\tName string\n\tGender string `xml:\"attr\"`\n\tAge int `xml:\"age\"`\n}\n```\n\n```\nxml: encoding \"Shift_JIS\" declared but Decoder.CharsetReader is nil\n```\n\n`Decoder.CharsetReader`がnilだと怒られています．なんとなくですが`xml.NewDecoder()`で受け取ったio.Readerとパーサの間に挟まって文字コードをUTF-8に変換してるんじゃないかなと思います．\n\n`Decoder.CharsetReader`の型を見ると，`func(charset string, r io.Reader) (io.Reader, error)`となっています．よくわからないけど`Decoder.CharsetReader`の戻り値が`transform.Reader`を返すような関数を実装すれば動きそうな感じがしたので，とりあえず書いてみたら動きました．\n\n```\npackage main\n\nimport (\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"golang.org/x/text/encoding/japanese\"\n\t\"golang.org/x/text/transform\"\n\t\"io\"\n\t\"os\"\n)\n\nfunc main() {\n\tfp, err := os.Open(\"taro.xml\")\n\tdefer fp.Close()\n\n\tvar user User\n\tdecoder := xml.NewDecoder(fp)\n\tdecoder.CharsetReader = func(charset string, r io.Reader) (io.Reader, error) {\n\t\treturn transform.NewReader(r, japanese.ShiftJIS.NewDecoder()), nil\n\t}\n\terr = decoder.Decode(\u0026user)\n\tif err != nil {\n\t\tfmt.Println(err.Error())\n\t}\n\tfmt.Printf(\"%#v\", user)\n}\n\ntype User struct {\n\tXMLName xml.Name `xml:\"user\"`\n\tName    string\n\tGender  string   `xml:\"attr\"`\n\tAge     int      `xml:\"age\"`\n}\n```\n\n`charset`にエンコーディングのタイプが渡されるので，CharsetReaderの中でエンコーディングごとに適した処理を書くのが本来のやり方っぽいですが，今回はShift_JISのXMLファイルをパースしたいだけなのでcharsetは無視しています．\n\n```\nmain.User{XMLName:xml.Name{Space:\"\", Local:\"user\"}, Name:\"太郎ちゃん\", Gender:\"Male\", Age:20}\n```\n\nこれでShift_JISのXMLファイルをパースすることが出来ました．🐘\n","cover":"","link":"2016/10/18.html","preview":"\u003cp\u003eShift_JISのXMLファイルをencoding/xmlで扱う方法\u003c/p\u003e\n","title":"Shift_JISのXMLをGoでパースする"},{"content":"\n\n# いままで: x-アプリ\n今まではパソコンかウォークマンで音楽を聴いていました．\n\nウォークマンを使っていたのでx-アプリでCDを取り込んでいました．今の時代SONY製品を使っているならMedia Goでリッピングするのがいいと何かで読んだ気がしますが，全く知りません．\n\nウォークマンを使っていたと言っても最近は使ってなかったのと，x-アプリでも音楽聴いていませんでした．たまにCDを買ったときにCDコンポで音楽を聴くくらい．そもそもノーミュージックノーライフみたいな人とは真逆の人間です．\n\nただ最近は買ったCDが溜まってきたのと，音楽を聴きたくなった時にわざわざCDコンポにCD入れたりするのが面倒になってきたのでなんとかしたいなーと思っていました．\n\nついでにx-アプリを使うのをやめました．普段使っているのはMBPなのでx-アプリ使えないし．\n\n# これから: iTunes + Google Play Music\nx-アプリから乗り換えということで，今持っているCDは全部iTunesで取り込みなおしました．全部取り込み終えたらライブラリには88枚のアルバムが入っていました．こうやってプラットフォームを変えた時にCDを取り込み直すのが本当にバカバカしくてやっていられないです，もうこれきりになるといいな．\n\nこれからはiTunesでCDを取り込み，パソコンで音楽を聴くときはiTunesで再生，スマホで聴くときはGoogle Play Musicでパソコン上のライブラリを同期して再生することにしました．\n\n今までスマホに音楽を入れたことがなかったのですが，結構便利そうです．スマホがすごいっていうかGoogle Play Musicがすごい．楽曲ファイルがあるディレクトリを指定すれば勝手にファイルをアップロードして曲情報取得してくれます．スマホにはPlay Musicをインストールするだけでいいのでとても楽．\n\n最初WAVEファイルで取り込んでいたんですが，Google Play Musicが対応してなかったのでALACで取り込み直しました．非圧縮やロスレス圧縮にこだわっているようなのですが余り耳が良くないのでストレージの無駄使いです完全に．\n\n# おわりに\n手元にCDやISOが無いアルバムがいくつかあってとても悲しいです．\n\n今回の感想としては，もともと音楽を熱心に聴かないのでこの辺りが便利になったところで猛烈に嬉しいってことはありませんでした．\n\nあと今回はじめてiTunesでアルバムを買いました．ムーンライダーズのDON'T TRUST OVER THIRTYです．🐘\n","cover":"","link":"2016/08/25.html","preview":"\u003cp\u003eいままでx-アプリでCDをリッピングしてたんですが，やめました\u003c/p\u003e\n","title":"音楽の再生環境を変えた"},{"content":"\n\nCGIカウンターとか懐かしくないですか?\n\n```\n#!/bin/sh\n\nfile=\"count.log\"\nlockfile=\"counter.lock\"\nsleeptime=0\n\nwhile :\ndo\n  #ロック\n  mktemp $lockfile 1\u003e /dev/null 2\u003e/dev/null\n  result=$?\n\n  #ロック出来てたらカウンタを進める\n  if [ $result -eq 0 ]; then\n    count=$((`cat $file` + 1))\n    echo $count \u003e count.log\n    #ロック開放\n    rm $lockfile\n    break\n  fi\n\n  sleeptime=$(($sleeptime + 1))\n  sleep \"0.00\"$sleeptime\ndone\n\necho $count\n```\n\n`count.log` というファイルを置いておけばカウンタとして動作します．ロックには `mktemp` を使いましたが `mkdir` とかでもいいはず．\n\nロックされてたら一定時間待つようにしていますが，ちょっと手抜きすぎるかも．\n","cover":"","link":"2016/08/22.html","preview":"\u003cp\u003eCGIカウンターとか懐かしくないですか?\u003c/p\u003e\n","title":"Shell ScriptでCGIカウンター"},{"content":"\n\ndstatでCPU使用率, メモリ, スワップ, ネットワークI/O, ディスクI/Oなどを取得してfluentdでElasticSearchに投げつけるというものです.\n\nそれをKibanaで視覚化します. ElasticSearch + Kibana + fluentd + dstatのやり方については他に紹介してるWebサイトがたくさんあるので割愛します.\n\ndstatだかfluentdのdstatプラグインの仕様が変わっているだかで, 参考にしたWebサイトの設定ファイルでは動きませんでした. ということで修正した `fluentd.conf` を紹介します.\n\n## fluent.conf\n\n``` text\n\u003csource\u003e\n  type config_expander\n  \u003cconfig\u003e\n    type dstat\n    tag host.dstat.__HOSTNAME__\n    option  -tclmsgr -dD sda,sdb --disk-util -nN eth0\n    delay 10\n  \u003c/config\u003e\n\u003c/source\u003e\n\n\u003cmatch host.dstat.**\u003e\n  type copy\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_usr\", time , \"cpu_usr\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"usr\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_sys\", time , \"cpu_sys\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"sys\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_idl\", time , \"cpu_idl\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"idl\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_wai\", time , \"cpu_wai\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"wai\"]]'\n  \u003c/store\u003e\n   \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_hiq\", time , \"cpu_hiq\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"hiq\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".cpu_siq\", time , \"cpu_siq\" =\u003e record[\"dstat\"][\"total_cpu_usage\"][\"siq\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".loadavg_1m\", time , \"loadavg_1m\" =\u003e record[\"dstat\"][\"load_avg\"][\"1m\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".mem_used\", time , \"mem_used\" =\u003e record[\"dstat\"][\"memory_usage\"][\"used\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".mem_buff\", time , \"mem_buff\" =\u003e record[\"dstat\"][\"memory_usage\"][\"buff\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".mem_cache\", time , \"mem_cache\" =\u003e record[\"dstat\"][\"memory_usage\"][\"cach\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".mem_free\", time , \"mem_free\" =\u003e record[\"dstat\"][\"memory_usage\"][\"free\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".io_sda_read\", time , \"io_sda_read\" =\u003e record[\"dstat\"][\"io/sda\"][\"read\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".io_sda_write\", time , \"io_sda_write\" =\u003e record[\"dstat\"][\"io/sda\"][\"writ\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".io_sdb_read\", time , \"io_sdb_read\" =\u003e record[\"dstat\"][\"io/sdb\"][\"read\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".io_sdb_write\", time , \"io_sdb_write\" =\u003e record[\"dstat\"][\"io/sdb\"][\"writ\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".dsk_sda_read\", time , \"dsk_sda_read\" =\u003e record[\"dstat\"][\"dsk/sda\"][\"read\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".dsk_sda_write\", time , \"dsk_sda_write\" =\u003e record[\"dstat\"][\"dsk/sda\"][\"writ\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".dsk_sdb_read\", time , \"dsk_sdb_read\" =\u003e record[\"dstat\"][\"dsk/sdb\"][\"read\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".dsk_sdb_write\", time , \"dsk_sdb_write\" =\u003e record[\"dstat\"][\"dsk/sdb\"][\"writ\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".sda_util\", time , \"sda_util\" =\u003e record[\"dstat\"][\"sda\"][\"util\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".paging_in\", time, \"paging_in\" =\u003e record[\"dstat\"][\"paging\"][\"in\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".paging_out\", time, \"paging_out\" =\u003e record[\"dstat\"][\"paging\"][\"out\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".swap_used\", time, \"swap_used\" =\u003e record[\"dstat\"][\"swap\"][\"used\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".net_eth0_recv\", time , \"net_eth0_recv\" =\u003e record[\"dstat\"][\"net/eth0\"][\"recv\"]]'\n  \u003c/store\u003e\n  \u003cstore\u003e\n    type map\n    map '[\"map.\" + tag + \".net_eth0_send\", time , \"net_eth0_send\" =\u003e record[\"dstat\"][\"net/eth0\"][\"send\"]]'\n  \u003c/store\u003e\n\u003c/match\u003e\n\n\u003cmatch map.host.dstat.**\u003e\n  type record_reformer\n  enable_ruby true\n  tag  timeadd.map.host.dstat\n  \u003crecord\u003e\n    hostname ${tag_parts[3]}\n  \u003c/record\u003e\n\u003c/match\u003e\n\n\u003cmatch timeadd.map.host.dstat.**\u003e\n  type typecast\n  item_types cpu_usr:float,cpu_sys:float,cpu_idl:float,cpu_wai:float,cpu_hiq:float,cpu_siq:float,loadavg_1m:float,mem_used:integer,mem_free:integer,mem_cache:integer,mem_buff:integer,io_sda_read:float,io_sda_write:float,io_sdb_read:float,io_sdb_write:float,dsk_sda_read:float,dsk_sda_write:float,dsk_sdb_read:float,dsk_sdb_write:float,sda_util:float,paging_in:float,paging_out:float,swap_used:integer,net_eth0_recv:float,net_eth0_send:float\n  tag  typecast.timeadd.map.host.dstat\n\u003c/match\u003e\n\n\u003cmatch typecast.timeadd.map.host.dstat.**\u003e\n  type elasticsearch\n  type_name       dstat\n  host            localhost\n  port            9200\n  logstash_format true\n  logstash_prefix logstash\n  flush_interval  10s\n\u003c/match\u003e\n```\n\n## ダッシュボード\n良い感じですがElasticSearchとKibanaはどちらもめちゃくちゃメモリを食います. 🐘\n\n![Kibana](/images/2016-06/26-kibana_screen_shot.png \"Kibana\")\n\n","cover":"","link":"2016/06/26.html","preview":"\u003cp\u003efluentdの設定ファイルを他所から丸パクリしたら動かなかった\u003c/p\u003e\n","title":"ElasticSearch + Kibanaでサーバのリソース監視"},{"content":"\n\nSoftetherの転送量をMuninでグラフ化する\u003ca href=\"https://github.com/dozen/softether-munin\" target=\"_blank\"\u003esoftether-plugin\u003c/a\u003eを作りました.\n\n今回は `Plugin::Munin`, `Plugin::Munin::Framework` を使いましたが, これらのモジュールを使った自作プラグインの作り方について解説しているサイトが全然見つからなかったので, 紹介します.\n\n情報少ないしこのモジュールはMunin v2.1以上じゃないと動かないし, 後述する `negative` を指定したグラフがたまにうまく描画できなかったりと, プラグインの作成方法としては結構微妙であることを先に書いておきます.\n\n## Plugin::Munin::Frameworkについて\nsoftether-pluginはPlugin::Munin::Frameworkというモジュールを使っていますが, これについての詳細はよくわかりません.\nというのも, このプラグインを書いたのは1年前で, 当時参考にしていたWebサイトが見つからなかったからです.\n\nMunin公式のプラグインで使われているようですがとにかくWeb上に情報が載ってないです.\nmunin 2.1.9-1では少なくともMunin公式のプラグインで `Munin::Plugin` , `Munin::Plugin::Framework` が使われています.\nしかし munin 2.0.25 ではそのようなプラグインは使用されておらず, またそれらを使ったプラグインは動きません. CPANにはこの2つのモジュールは無かったので, これらのモジュールを使いたい場合は対応したバージョンのmuninをインストールするしかなさそうです.\n\nそんなよくわからないものを使って大丈夫なのかよという感じですが, 動くし, 簡単にプラグインが書けるっぽいのでよしとします.\n\n## 自作プラグインで実現したいこと\nプラグインを自作する上で実現したいのは以下の3つです.\n\n1. softether_myhub のようなシンボリックリンクを張るとmyhubのグラフを作ってくれる\n1. Softetherのホスト名とかHubのパスワードはmunin-node.conf.d/munin-nodeにかける\n1. Virtual HUB単位で転送量, パケット数をグラフ化\n\nグラフ化できることはもちろんですが, Muninのプラグインらしく, シンボリックリンクで監視対象のデバイスを指定したり, munin-node.conf.d/munin-node に書いたconfigが読めるようにしたいです.\n\n## プラグインの作成\nsoftether-muninのソースコードを使って解説していきます.\n\n### シンボリックリンク名でVirtual Hubを指定\nMuninのプラグインでありがちな, 実体が `if_` というファイルで `if_eth0` というシンボリックリンクを張るとeth0についてのグラフを作成する, というのを真似したい.\n\nプラグイン `softether_` のシンボリックリンク名を読み取る部分はこうなります.\n\n``` perl\nmy $hub;\n\nif ($0 =~ /softether_([\\w\\d#-_.\u0026]+)$/) {\n  $hub = $1;\n} else {\n  die (\"Can't run config without a symlinked name\");\n}\n```\n\nこれで `softether_myhub` というシンボリックリンクを張れば `$hub` に `myhub` が入り, あとで好きに使えます.\n\n### munin-node.conf.dにあるConfigを読み込む\nホスト名, パスワード, vpncmdのパスを設定ファイルから読み込めるようにします.\n\nソースコードはこんな感じです.\n\n``` perl\nunless (defined $ENV{host}) {\n  $ENV{host} = \"localhost\";\n}\n\nunless (defined $ENV{password}) {\n  die (\"Please set password\");\n}\n\nunless (defined $ENV{vpncmdpath}) {\n  $ENV{vpncmdpath} = \"/usr/local/vpnserver/vpncmd\";\n}\n```\n\n対応するmunin-node.conf.dの設定は以下のようになります\n\n```\n[softether_*]\nenv.password myvpnpassword\nenv.host localhost\nenv.vpncmdpath /usr/local/vpnserver/vpncmd\n```\n\nホスト名とvpncmdのパスはデフォルト値をプラグインのソースコードで指定しているので, 設定ファイルには書かなくても動きます.\n設定ファイルに `env.password` と書いた場合はPerlの場合だと `$ENV{password}` みたいな感じでアクセスできるみたいです.\n\n### 値の取得とか, 描画したいグラフの設定\n\n``` perl\nmy @item_key = (\n\"Outgoing Unicast Packets\",\n\"Outgoing Unicast Total Size\",\n\"Outgoing Broadcast Packets\",\n\"Outgoing Broadcast Total Size\",\n\"Incoming Unicast Packets\",\n\"Incoming Unicast Total Size\",\n\"Incoming Broadcast Packets\",\n\"Incoming Broadcast Total Size\",\n);\n\nmy $result = `$ENV{vpncmdpath} $ENV{host} /SERVER /password:$ENV{password} /hub:$hub /cmd StatusGet`;\n\nmy %data;\n\nsub get_value {\n  my $tmp;\n  my $key = shift;\n  if ($result =~ /$key\\s*\\|([0-9,]+)/) {\n    $tmp = $1;\n    $tmp =~ s/,//g;\n    return $tmp;\n  }\n}\n\nfor my $item (@item_key) {\n  $data{$item} = get_value($item);\n}\n```\n\nこんな感じです.  `$result` には以下のような結果が入るので, 欲しい値を `@item_key` に登録しておいて取って来ています\n\n```\nStatusGet\nvpncmd command - SoftEther VPN Command Line Management Utility\nSoftEther VPN Command Line Management Utility (vpncmd command)\nVersion 4.19 Build 9605   (English)\nCompiled 2016/03/06 21:09:57 by yagi at pc30\nCopyright (c) SoftEther VPN Project. All Rights Reserved.\n\nConnection has been established with VPN Server \"localhost\" (port 443).\n\nYou have administrator privileges for Virtual Hub 'vpn' on the VPN Server.\n\nVPN Server/vpn\u003eStatusGet\nStatusGet command - Get Current Status of Virtual Hub\nItem                         |Value\n-----------------------------+---------------------\nVirtual Hub Name             |vpn\nStatus                       |Online\nType                         |Standalone\nSecureNAT                    |Enabled\nSessions                     |2\nSessions (Client)            |1\nSessions (Bridge)            |0\nAccess Lists                 |0\nUsers                        |1\nGroups                       |0\nMAC Tables                   |3\nIP Tables                    |3\nNum Logins                   |54\nLast Login                   |2016-06-25 19:12:43\nLast Communication           |2016-06-25 21:22:15\nCreated at                   |2016-04-04 00:12:46\nOutgoing Unicast Packets     |157,138,736 packets\nOutgoing Unicast Total Size  |133,078,817,603 bytes\nOutgoing Broadcast Packets   |477,735 packets\nOutgoing Broadcast Total Size|31,355,040 bytes\nIncoming Unicast Packets     |157,166,519 packets\nIncoming Unicast Total Size  |133,081,898,141 bytes\nIncoming Broadcast Packets   |2,833,614 packets\nIncoming Broadcast Total Size|174,223,220 bytes\nThe command completed successfully.\n```\n\n### Munin::Plugin::Framework でグラフ作成\nMuninのプラグインは引数にconfを渡した時はグラフの設定を吐かないといけなかったりとか色々あるんですが, そのへんをよしなにやってくれるのが `Munin::Plugin::Framework` です. だと思います.\n\nこれを使えば設定ファイルを書くイメージでサクサクっとプラグインを作れます.\n\n``` perl\nmy $plugin = Munin::Plugin::Framework-\u003enew;\n\n$plugin-\u003eadd_graphs(\n  packets =\u003e {\n    args =\u003e \"\",\n    category =\u003e $category,\n    info =\u003e \"$hub Packets\",\n    title =\u003e \"$hub Packets\",\n    vlabel =\u003e \"in (-) | out (+) packets / second\",\n    fields =\u003e {\n      unicast_out =\u003e {\n        label =\u003e \"Unicast\",\n\ttype =\u003e \"DERIVE\",\n\tmin =\u003e 0,\n\tnegative =\u003e \"unicast_in\",\n\tvalue =\u003e $data{\"Outgoing Unicast Packets\"}\n      },\n      unicast_in =\u003e {\n        type =\u003e \"DERIVE\",\n\tmin =\u003e 0,\n\tvalue =\u003e  $data{\"Incoming Unicast Packets\"}\n      }\n    }\n  },\n  unicast_total_packets =\u003e {\n    args =\u003e \"\",\n    category =\u003e $category,\n    info =\u003e \"$hub Unicast Toatl Packets\",\n    title =\u003e \"$hub Unicast Total Packets\",\n    vlabel =\u003e \"packets\",\n    fields =\u003e {\n      incoming =\u003e {\n        label =\u003e \"Incoming\",\n        type =\u003e \"GAUGE\",\n        min =\u003e 0,\n        value =\u003e $data{\"Incoming Unicast Packets\"}\n      },\n      outgoing =\u003e {\n        label =\u003e \"Outgoing\",\n        type =\u003e \"GAUGE\",\n        draw =\u003e \"AREA\",\n        min =\u003e 0,\n        value =\u003e $data{\"Outgoing Unicast Packets\"}\n      }\n    }\n  }\n);\n\n$plugin-\u003erun();\n```\n\nこんな感じで `add_graphs()` でどんどん追加していくだけ.\nカテゴリは `softether` とかにしてます.\n\n- args: グラフの下限値, 上限値, 対数スケールでプロット などを指定するところ\n- category: [ disk munin network processes system time ]みたいなの, あれです. すでにあるものに追加したりとか, `softether` みたいに新しいカテゴリを作ることも出来ます\n- vlabel: グラフの縦軸の表示名.\n- fields: 描画したいデータについて記述する\n  - type: `DERIVE` だと前の値との差, `GAUGE` だと値をそのまま出力\n  - negative: NICのスループットとかのグラフでoutが上方向, inが下方向にグラフが伸びてますが, あれを実現するためのものです. `negative` に指定したキーのフィールドがマイナス方向に描画されるようになります.\n\nだいたいこんな感じなんですが, `Munin::Plugin::Framework` で `negative` を指定するとたまーにグラフの生成に失敗します.\nRRDToolがエラーを吐いてますが, 原因はよくわかりません. この辺はちょっと微妙な感じですね.\n`negative` を使わなければいいんですがSoftetherプラグインでグラフ化したいものはおおかたIn/OutがあるのでOutを上方向, Inを下方向に伸ばすグラフのほうがしっくり来ますし.\n\n### プラグインの全体図, 生成されるグラフ\n\u003ca href=\"https://github.com/dozen/softether-munin\" target=\"_blank\"\u003egithub\u003c/a\u003eを見てください. 🐘\n","cover":"","link":"2016/06/25.html","preview":"\u003cp\u003ePlugin::Munin, Plugin::Munin::Frameworkを使ってMunin pluginを自作する\u003c/p\u003e\n","title":"Munin pluginの作成"},{"content":"\n\n## InkPaperの使い方\n[InkPaperのREADME](https://github.com/InkProject/ink#introduce)を読めばだいたい分かる.\n\n### InkPaperをインストール\n[http://www.inkpaper.io/](http://www.inkpaper.io/)から自分の環境に合ったものをダウンロードします. zipファイルを解凍すればインストールは完了です.\n\n### 設定ファイルを編集する\n`blog/config.yml`を編集します.\n\n```\nsite:\n    title: ジェット・ゾウ #ブログのタイトル\n    subtitle: サブタイトル #タイトルの下にチョロンと表示されます\n    # logo: /images/avatar.jpg #トップページに表示される自分のアイコン\n    limit: 10 \n    theme: theme\n    disqus: somebody\n    lang: en\n    url: http://jetzou.com/\n    # root: /blog\n\nauthors:\n    me:\n        name: dozen\n        intro: どぜんと読みます\n        avatar: /images/avatar.jpg\n\nbuild:\n    port: 8000\n    # Copied files to public folder when build\n    copy:\n        - theme/bundle\n        - theme/favicon.ico\n        - theme/robots.txt\n        - source/images\n    # Excuted command when use 'ink publish'\n    publish: |\n        git add . -A\n        git commit -m \"update\"\n        git push origin\n```\n\n`url`と`root`だけ気をつければあとは適当で大丈夫. 今回は`http://jetzou.com/`で公開したいので`url: http://jetzou.com/\"`としました. `disqus`はコメント機能を提供してくれるDISQUSのアカウントを指定するんですが, 今回はスキップ.\n\n`lang`は今のところ中国語と英語にしか対応していないみたいなので, `en`を指定しました.\n\n設定ファイルはこんな感じで大丈夫そうです.\n\n### 記事を書く\n記事を置く場所は`blog/source`です.\n\nインストールした状態ではサンプルページの`blog/source/ink-blog-tool-en.md`と`blog/source/ink-blog-tool.md`があります. 記事を書くまえにこのファイルをみて, 参考にするといいです. 公開する前にこの2つのファイルは消しておきます.\n\n```\ntitle: Article Title\ndate: Year-Month-Day Hour:Minute:Second #Created Time，Support TimeZone, such as \" +0800\"\nupdate: Year-Month-Day Hour:Minute:Second #Updated Time，Optional，Support TimeZone, such as \" +0800\"\nauthor: AuthorID\ncover: Article Cover Path #Optional\ndraft: false #If Draft，Optional\ntop: false #Place article to top, Optional\npreview: Article Preview，Also use \u003c!--more--\u003e to split in body #Optional\ntags: #Optional\n    - Tag1\n    - Tag2\n\n---\n\nMarkdown Format's Body\n```\n\n`date`は投稿日時, `update`は更新日時です. `update`は不要ですが`date`は必須です. トップページなどを生成する際に`date`をもとに記事をソートするためです. フォーマットは`2016-06-01 12:00:00`みたいな感じです. ちゃんと秒まで指定しないとエラーが出ます.\n\n`author`は`blog/config.yml`で指定した`authors`を指定します. デフォルトだと`me`です. \n\n`cover`はよくわかんないです. アイキャッチかな?\n\n`draft: true`を追加すると書きかけの記事とみなされて, ページが生成されません.\n\n`top: true`とすると, トップページの一番上に張り付く記事になるみたいです. 使ったこと無いからわからないけど.\n\n`preview`はトップページで表示される記事の概要を指定します. これを指定せずに, 記事の本体の適当な場所に`\u003c!--more--\u003e`を置くとその部分までを記事の概要として表示してくれます. ただし, Markdownを処理してくれないので`\u003c!--more--\u003e`は使わずに, `preview`を指定することをおすすめします.\n\n`tags`で`PC`とか`食べ物`とか指定してあげるとタグごとのアーカイブページとか作ってくれます.\n\n以上が記事の情報です. `---`より下が本文となります. ここから下はMarkdown記法が使えます.\n\nこれを踏まえると一番簡単な書式はこうなります.\n\n```\ntitle: タイトル\ndate: 2016-06-05 7:00:00\npreview: テストです\n\n---\n\nテスト\n```\n\nこれを`blog/source`の下に置いて, ファイル名を`タイトル.md`などとして保存してもいいのですが, それだと今後記事が増えた時にひっちゃかめっちゃかになる可能性が高いです.\n\nそこで, `blog/source/年/月/日`というふうにサブディレクトリを作るのがおすすめです. サブディレクトリを作っても記事のURIには何の影響も出ないので, 好きなように変更できます. 私は今のところ`blog/source/年/月`くらいにしてます.\n\n### ちゃんと生成されてるかチェックする\n記事を書いたら, ちゃんとページが生成されるかテストしてみます. `./ink preview`というコマンドを実行することで, ページを生成して簡易的なサーバが起動します. `http://localhost:8000`でアクセスできます. ポート番号が8000だと都合がわるい場合は`blog/config.yml`で変更します.\n\n### テーマを修正する\nブログが生成されているかチェックすると, あることに気づきます. 投稿した時刻がおかしいんです. 設定ファイルで英語を指定したはずなのに,`分钟前`とか表示されます. どうもこの投稿時刻の表示はJavascriptで行われており, ここだけ言語の設定が反映されないみたいです.\n\n#### まじめに直す\nテーマは`blog/theme`にあり, 編集すべきファイルは`blog/theme/source/index.coffee`です.\n\n```\ntimeSince = (date) -\u003e\n\n    seconds = Math.floor((new Date() - date) / 1000)\n    interval = Math.floor(seconds / 31536000)\n    if interval \u003e 1\n        return interval + \"年前\"\n    interval = Math.floor(seconds / 2592000)\n    if interval \u003e 1\n        return interval + \"个月前\"\n    interval = Math.floor(seconds / 86400)\n    if interval \u003e 1\n        return interval + \"天前\"\n    interval = Math.floor(seconds / 3600)\n    if interval \u003e 1\n        return interval + \"小时前\"\n    interval = Math.floor(seconds / 60)\n    if interval \u003e 1\n        return interval + \"分钟前\"\n    return Math.floor(seconds) + \"秒前\"\n```\n\nこんな記述があるので, 以下のように変更します.\n\n```\ntimeSince = (date) -\u003e\n\n    seconds = Math.floor((new Date() - date) / 1000)\n    interval = Math.floor(seconds / 31536000)\n    if interval \u003e 1\n        return interval + \"年前\"\n    interval = Math.floor(seconds / 2592000)\n    if interval \u003e 1\n        return interval + \"ヶ月前\"\n    interval = Math.floor(seconds / 86400)\n    if interval \u003e 1\n        return interval + \"日前\"\n    interval = Math.floor(seconds / 3600)\n    if interval \u003e 1\n        return interval + \"時間前\"\n    interval = Math.floor(seconds / 60)\n    if interval \u003e 1\n        return interval + \"分前\"\n    return Math.floor(seconds) + \"秒前\"\n```\n\n編集が終わったら, webpackを実行します.\n\n`blog/theme`に移動して, 以下のコマンドを実行します.\n\n```\nnpm install\n\n./node_modules/webpack/bin/webpack.js\n```\n\n次に`ink`とか`blog`があるディレクトリに戻って, `./ink preview`を実行して確認してください. `10分前`みたいなかんじになっているはずです.\n\n#### 適当に直す\nnodeとか入れてないしjsファイル直接編集するだけでいいでしょ, って言う方はこっちで.\n\n`blog/theme/bundle/index.js`の1行目に, `个月前`とか`天前`とか書いてある部分があるはずなので, 修正します.\n\n`./ink preview` で変更が反映されていることを確認します.\n\n### コマンドまとめ\n記事を書いたら`./ink preview`で確認して, `./ink publish`でGithubにプッシュ, という流れになります. `./ink build`はテーマからcssやjsファイルをコピーしてくるコマンドですが, `preview`や`publish`のときにこのコマンドが走っているみたいなので自分で実行する必要がなく, 余り使いません\n\n\n## Github Pagesの使い方\n[https://help.github.com/categories/github-pages-basics/](https://help.github.com/categories/github-pages-basics/)を読めばだいたい分かる.\n\n### リポジトリの作成とCNAMEの設定\ngithubで`blog`とか適当な名前のリポジトリを作ります. そうしたら, `blog`ディレクトリに移動して先ほど作ったリポジトリをcloneします. 次に`blog/public`を削除し, cloneしたリポジトリのを`public`にリネームします. リネームしたら`git checkout -b gh-pages`を実行します.\n\n`blog/public/CNAME`ファイルを作成し, 使用するドメインをファイルの1行目に書き込みます. `jetzou.com`とか, `blog.jetzou.com`みたいな感じです. 書き込んだら, `git add CNAME`, `git commit -m \"add CNAME\"`というふうにCNAMEファイルを追加し,コミットしてください. \n\nコミットしたら, `git push --set-upstream origin gh-pages` を実行しておきます.\n\nCustom Domainを使わずに`dozen.github.io/blog`みたいな感じで使う人は`CNAME`ファイルの設定は不要です.\n\n### DNSの設定\nCustom Domain使う人だけが必要な設定です. [https://help.github.com/articles/setting-up-an-apex-domain/\u003cPaste\u003e](https://help.github.com/articles/setting-up-an-apex-domain/)ここを参考にします.\n\n参考にするページにも書いてありますが, CNAMEレコードは使わないようにします. で, 今回はALIAS, ANAMEレコード非対応のDNSサービスを利用するため, Aレコードを使った設定をします.\n\nDNSに`192.30.252.153`と`192.30.252.154`のAレコードを追加すればいいっぽいので, 追加します.\n\n### InkPaperの設定ファイルを修正する\n`blog/config.yml`の`utl`を変更します. 必要な場合は`root`をアンコメントします.\n\n### 記事をGithub Pagesに反映\nここまでの設定を終えて, 記事を書いたら`./ink publish`を実行します. これで, Github Pages上のブログにアクセスできるようになっているはずです\n\n---\n\nInkPaperとGithub Pagesの使い方はざっとこんな感じです.\n\nInkPaperに関する日本語の記事があんまりないのが悲しいです. 日本で使ってる人が増えたらいいな. 🐘\n","cover":"","link":"2016/06/05.html","preview":"\u003cp\u003eInkPpaerでブログを生成して, Github Pagesにアップロードするまで\u003c/p\u003e\n","title":"InkPaperとGithub Pagesの使い方"},{"content":"\n\n## ブログを静的サイトにするわけ\nブログをやっていて, サイトに変更が必要なシーンは以下のとおりです.\n\n- 新しい記事を書いた時\n- コメントがついた時\n- トラックバックがあった時\n\nたったこれだけ. しかも, コメントはSNSで代用できるし, トラックバックは廃れてるから不要です. となると, サイトに変更が加わるのは新しい記事を書いた時だけということになります. 静的サイトで十分ですよね.\n\n実際にTwitterとかFacebookが普及した頃にWordPressから静的サイトジェネレータに移行しましたっていうのが流行ってました.\n\n静的サイトジェネレータとか静的ブログジェネレータの類が, 今回のInkPaperにあたります.\n\n## [InkPaper](https://github.com/InkProject/ink)とは\nGo言語で書かれた静的ブログジェネレータです. 今回はこれを使いました.\n\nブログって静的サイトで十分だよね, とは言いつつも新しい記事を書いた時に更新が必要になるページは結構たくさんあります. トップページ, アーカイブのページ, カテゴリのページなど… これらを手作業でするのは面倒すぎます. そういう時に静的サイトジェネレータが必要です.\n\nInkPaperを選んだのは単純にGo言語で書かれてるからっていう理由だけです. たまたま今Goを触っているので.\nそれとMarkdownで記事をかけるのが良い感じです.\n\n## ホスティング\n自鯖やVPSでブログをやってた頃があるんですが, ブログの引越は結構面倒くさいんですよねー. それがだるくて今までブログを立てるたびに前のブログの記事が失われていました.\n\nそういうのを防ぐために, 今回は[Github Pages](https://pages.github.com/)を使いました. サーバの管理とか無いので, ブログが失われることは無いと思います.\n\n## InkPaperとGithub Pagesを使ってみた感想\n\n悪く無いと思いますが, 気になることが少なくないです.\n\nInkPaperはちょっとシンプルすぎるかも. Analyticsを仕込む機能が無いので, 自分でテンプレートのフッターにトラッキングコードを加えないといけませんでした.\n\nあとURIの構造を自分好みに変更できない. パーマリンクの設定とか無いので, URIは `年/月/日/記事のファイル名.html` となります.\n\n# まとめ\nInkPaperとGithub Pagesを使ってブログを立てたことをエントリーにしてみたんですが, 案外気になる点が多かったです. これ長続きしないかもしれないなあ… 🐘\n","cover":"","link":"2016/06/03.html","preview":"\u003cp\u003eGo言語製の静的ブログジェネレータ, InkPaperを使います\u003c/p\u003e\n","title":"Github PagesとInkPaperでブログを始める"}]